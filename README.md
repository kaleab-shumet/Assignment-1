## Assignment-1

### Transistors
Transistors are basic components in all of today's electronics. They are just simple switches that we can use to turn things on and off. Even though they are simple, they are the most important electrical component. For example, transistors are almost the only components used to build a Pentium processor. A single Pentium 4 chip has about 55 million transistors (which is why these chips get so darn hot). The ones in the Pentium are smaller than the ones we will use but they work the same way.

Transistors are at the very core of today's electronics technology. The development of the bipolar transistor or bipolar junction transistor, BJT, has resulted in many changes to the world.

The introduction of the bipolar transistor has enabled many technologies we take for granted today: everything from portable transistor radios, through to mobile phones, and computers, remote operation, the functionality we take for granted in current day automobiles, etc . . . . All these and many more everyday items have all been made possible by the invention of the transistor.

Today, bipolar transistors are available in many forms. There is the basic transistor in a leaded form or its available as a surface mount transistor. But transistors are also widely used within integrated circuits. Most digital ICs use field effect technology, but many analogue ICs use bipolar technology to provide the required performance.

Together with their field effect transistor, FET, relatives which use a very different principle, the bipolar transistor forms the basis of most of todays electronic equipment, either as discrete devices or within integrated circuits.


### More's Law
Moore's Law states that the number of transistors on a microchip doubles every two years. The law claims that we can expect the speed and capability of our computers to increase every two years because of this, yet we will pay less for them. Another tenet of Moore's Law asserts that this growth is exponential. The law is attributed to Gordon Moore, the co-founder and former CEO of Intel.

### Lambda Calculus
The λ -calculus is, at heart, a simple notation for functions and application. The main ideas are applying a function to an argument and forming functions by abstraction. The syntax of basic λ-calculus is quite sparse, making it an elegant, focused notation for representing functions. Functions and arguments are on a par with one another. The result is a non-extensional theory of functions as rules of computation, contrasting with an extensional theory of functions as sets of ordered pairs. Despite its sparse syntax, the expressiveness and flexibility of the λ-calculus make it a cornucopia of logic and mathematics. This entry develops some of the central highlights of the field and prepares the reader for further study of the subject and its applications in philosophy, linguistics, computer science, and logic.

### How computers work ?
A computer, a digital information-processing machine, works by changing information into binary numbers (ones and zeros) and then using simple mathematics to make decisions about how to rearrange those numbers into words or actions. A digital system stores and operates on information in a very specific way by storing information in a bit (or multiple collections of bits). A bit is a variable that can have only one of two values: it can either be a 1, or be a 0. 
